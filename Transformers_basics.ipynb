{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMzf63jOlMGBsWPAY9Lfu3X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RajanIsBack/GenAI/blob/main/Transformers_basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlfsEGflU727",
        "outputId": "372b3f40-b59d-457f-db14-8ef496fbe54a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to google-t5/t5-base and revision a9723ea (https://huggingface.co/google-t5/t5-base).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translation: [{'translation_text': 'Bonjour, comment Ãªtes-vous?'}]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized text -->: [{'summary_text': 'Transformers are a family of deep learning models introduced in the paper \"Attention is All You Need\" in 2017. These models have since revolutionized Natural Language Processing (NLP) by providing state-of-the-art results'}]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "No model was supplied, defaulted to facebook/bart-large-mnli and revision d7645e1 (https://huggingface.co/facebook/bart-large-mnli).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment Analysis: [{'label': 'POSITIVE', 'score': 0.9998807907104492}]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zero-Shot Classification: {'sequence': 'The movie was fantastic!', 'labels': ['positive', 'neutral', 'negative'], 'scores': [0.9887009859085083, 0.006698090583086014, 0.004600969608873129]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cuda:0\n",
            "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 564e9b5 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Named Entity Recognition (NER): [{'entity': 'I-ORG', 'score': 0.9990183, 'index': 1, 'word': 'Apple', 'start': 0, 'end': 5}, {'entity': 'I-LOC', 'score': 0.9996722, 'index': 6, 'word': 'U', 'start': 27, 'end': 28}, {'entity': 'I-LOC', 'score': 0.9979365, 'index': 8, 'word': 'K', 'start': 29, 'end': 30}]\n",
            "Question Answering: {'score': 0.33481359481811523, 'start': 91, 'end': 145, 'answer': 'self-attention mechanisms to process and generate text'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fill in the Blank (Fill Mask): [{'score': 0.16044218838214874, 'token': 2373, 'token_str': 'power', 'sequence': 'transformers are a type of power model.'}, {'score': 0.12710227072238922, 'token': 5992, 'token_str': 'electrical', 'sequence': 'transformers are a type of electrical model.'}, {'score': 0.04157041758298874, 'token': 6228, 'token_str': 'mechanical', 'sequence': 'transformers are a type of mechanical model.'}, {'score': 0.023679807782173157, 'token': 19081, 'token_str': 'transformers', 'sequence': 'transformers are a type of transformers model.'}, {'score': 0.019131235778331757, 'token': 4816, 'token_str': 'electronic', 'sequence': 'transformers are a type of electronic model.'}]\n"
          ]
        }
      ],
      "source": [
        "# Transformers can do lot of things\n",
        "# Below are various examples\n",
        "\n",
        "from transformers import pipeline\n",
        "# 1. Translation: Translate text from one language to another\n",
        "translation_pipeline = pipeline(\"translation_en_to_fr\")  # English to French translation\n",
        "translation_result = translation_pipeline(\"Hello, how are you?\")\n",
        "print(\"Translation:\", translation_result)\n",
        "\n",
        "# 2. Text Summarization: Summarize a long piece of text\n",
        "summarization_pipeline=pipeline (\"summarization\",model=\"facebook/bart-large-cnn\")\n",
        "long_text =\"\"\"\n",
        "Transformers are a family of deep learning models introduced in the paper \"Attention is All You Need\" in 2017.\n",
        "These models have since revolutionized Natural Language Processing (NLP) by providing state-of-the-art results\n",
        "on a wide range of tasks, such as machine translation, text generation, and question answering. The key innovation\n",
        "of transformers is the self-attention mechanism, which allows the model to weigh the importance of different words\n",
        "in a sentence, regardless of their distance from each other. This enables transformers to better handle long-range dependencies.\n",
        "\"\"\"\n",
        "summarization_result= summarization_pipeline(long_text, max_length=50,min_length=25,do_sample=False)\n",
        "print(\"Summarized text -->:\", summarization_result)\n",
        "\n",
        "# 3. Sentiment Analysis: Determine the sentiment of a text (positive/negative)\n",
        "sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
        "sentiment_result = sentiment_pipeline(\"I love using transformers! They're amazing.\")\n",
        "print(\"Sentiment Analysis:\", sentiment_result)\n",
        "\n",
        "# 4. Zero-Shot Classification: Classify text into categories without prior training\n",
        "zero_shot_pipeline = pipeline(\"zero-shot-classification\")\n",
        "zero_shot_result = zero_shot_pipeline(\"The movie was fantastic!\", candidate_labels=[\"positive\", \"negative\", \"neutral\"])\n",
        "print(\"Zero-Shot Classification:\", zero_shot_result)\n",
        "\n",
        "# 5. Named Entity Recognition (NER): Extract named entities from a sentence\n",
        "ner_pipeline = pipeline(\"ner\", model=\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n",
        "ner_result = ner_pipeline(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
        "print(\"Named Entity Recognition (NER):\", ner_result)\n",
        "\n",
        "# 6. Question Answering: Answer a question based on provided context\n",
        "qa_pipeline = pipeline(\"question-answering\")\n",
        "context = \"\"\"\n",
        "Transformers are a type of deep learning model that has been widely used in NLP.\n",
        "They use self-attention mechanisms to process and generate text, and have been applied to a wide range of tasks,\n",
        "from language translation to sentiment analysis.\n",
        "\"\"\"\n",
        "qa_result = qa_pipeline(question=\"What are transformers used for?\", context=context)\n",
        "print(\"Question Answering:\", qa_result)\n",
        "\n",
        "# 7. Fill in the Blank (Fill Mask): Predict a masked word in a sentence\n",
        "fill_mask_pipeline = pipeline(\"fill-mask\", model=\"bert-base-uncased\")\n",
        "fill_mask_result = fill_mask_pipeline(\"Transformers are a type of [MASK] model.\")\n",
        "print(\"Fill in the Blank (Fill Mask):\", fill_mask_result)\n"
      ]
    }
  ]
}